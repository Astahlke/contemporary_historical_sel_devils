These files are the most current results of three types of selection
analyses done on the RAD-capture dataset. When I (Brendan) put these
results together, I no longer had access to IBEST, so I drew from the files
I had downloaded to my laptop - there may be stuff that you want from
IBEST too, so I've provided the locations of files on IBEST; unless noted
otherwise, all the paths start with /mnt/gfs/bepstein/devilsrapture; you
can also check under "lfs2" (the Lustre filesystem) if you can't find
something in gfs. Almost all the scripts are in the "scripts" or
"scripts/batch" directory, plus time-stamped copies of the batch scripts
were automatically saved to the output directories every time I ran
them.

Last updated: 06 May 2017 by Brendan


OVERVIEW
=========

Three types of selection analyses:
    - Allele frequency change from pre- to post-DFTD in each population
      at each SNP
    - Mathieson & McVean 2013 selection strength analysis that uses
      allele frequency (really counts) at multiple time points to
      estimate the strength of selection in each population separately;
      produces a result for each SNP
    - spatpg: Zach Gompert's program for estimating the strength of
      selection in response to an environmental factor (in this case,
      the presence of DFTD) at each SNP


METHODS
=========

All of the analyses used ANGSD as input, which means they did not rely
on individual genotype calls, though they did rely on ANGSD behaving
itself and Brendan understanding how to use ANGSD properly (both are
somewhat dubious assumptions).

Allele frequency change
-------------------------

    Five populations included: Fentonbury, Forestier, Freycinet,
        Narawntapu, and West Pencil Pine

    We have no pre-DFTD samples from Mt. William, and Woolsnorth has not
    (or had not) been infected yet. I lumped all samples collected before
    or during the first year of infection into pre- and all the rest into
    post-. Note that it was the year that I had listed for DNA collection
    that was used. There were a couple individuals sampled in multiple
    years - these were counted in all of those years.

    | Population       | First year of DFTD |
    |------------------+--------------------|
    | Fentonbury       |               2005 |
    | Forestier        |               2004 |
    | Freycinet        |               2001 |
    | Narawntapu       |               2007 |
    | West Pencil Pine |               2006 |

    Workflow:
    1.  Estimate allele frequency in pre- and post-DFTD populations
        with ANGSD. The script that did that is angsd_2016-01-15.sh,
        under the "simple-run" task (following the "prep" and
        "bamlist" tasks). This is where samples were divided into
        pre- and post-DFTD sets. Note that the result of this is a
        set of allele frequencies - the .mafs.gz files on IBEST.
        IBEST directory: results/aln_geno_analysis/alignments/bowtie2_rapture_2015_allref_150904/next/aln_filter/2016-01-13/next/af_est/angsd_2016-01-15/results
    2.  Filter sites (each population separately): 
            p <= 0.000001 (test of whether site is a SNP)
            >= 10 individuals with some reads
            MAF >= 0.05 in at least one time point  
        Then, subtract pre-DFTD allele frequency from post-DFTD
        allele frequency. These steps were done by
        afchange_2016-01-26.sh.
        IBEST directory: results/aln_geno_analysis/alignments/bowtie2_rapture_2015_allref_150904/next/aln_filter/2016-01-13/next/af_est/angsd_2016-01-15/next/afchange_2016-01-26/results
    3.  Psuedo p-values were calculated - they are just based on the
        quantile of abs(allele frequency change) - using the
        quantile_to_p.r script. I don't think this is a very
        important step, but it's the step for which I have files on
        my own computer, so that's what you're going to get. Note
        that the "p-values" do not take into account the amount of
        support for a change in allele frequency (e.g. number of
        strains with data, etc.), they are just ranking SNPs by
        magnitude of change The overall script is
        composite_stat_2016-10-17.sh.
        IBEST directory: results/aln_geno_analysis/alignments/bowtie2_rapture_2015_allref_150904/next/aln_filter/2016-01-13/next/af_est/angsd_2016-01-15/next/composite_stat/2017-10-17/results

Mathieson & McVean time series analysis
----------------------------------------

    Six populations included: Fentonbury, Forestier, Freycinet, Mt.
    William, Narawntapu, and West Pencil Pine. First years with DFTD are
    the same as listed above for the allele frequency change analysis.

    This analysis grouped samples into two year cohorts, starting with
    the first year of DFTD infection (or the earliest year with samples)
    and used the M&M R code to test for and estimate the strength of
    selection based on the trajectory of allele frequencies. To do this,
    M&M requires a estimate of effective population size; this step is
    pretty sketchy, and I was never able to get estimates from the
    rapture data. Instead, I used NeEstimator estimates from the full
    RAD dataset for Freycinet, Narawn. and WPP and took an educated
    guess at the others. I'm pretty sure Ne is assumed to be constant.

    | Population       | Ne estimate |
    |------------------+-------------|
    | Fentonbury       |          35 |
    | Forestier        |          35 |
    | Freycinet        |          34 |
    | Mt. William      |          35 |
    | Narawntapu       |          37 |
    | West Pencil Pine |          26 |

    NOTE: Unlike the allele frequency change analysis, individuals are
    grouped into years by their date of birth - so the analysis should
    (if I did all the data processing correctly) have been run on ind's
    born after DFTD infected a population.

    Also, this method produces actual p-values. I don't know how
    robust/accurate they are, but they aren't one of my made-up
    pseudo-p-value things.

    Workflow:
    1.  Estimate allele frequencies with ANGSD. The same as the methods
        for the allele frequency change, but I used a different script
        that lumped samples into cohorts by year of birth. The script
        is: angsd_2016-03-13.sh.
        IBEST directory: results/aln_geno_analysis/alignments/bowtie2_rapture_2015_allref_150904/next/aln_filter/2016-01-13//next/af_est/angsd_2016-03-13/results
    2.  Convert allele frequencies into allele counts (just multiply
        frequency by number of samples and round to an integer). Filter
        SNPs: 
            p-value < 0.000001
            MAF >= 0.05 in at least 5 combinations of population and
                cohort (Why 5? Well, it gave a manageable number of SNPs
                to test.)
            Minor allele count >= 3 in at least 5 pop/cohort combos
    3.  Then run the M&M code, which is in slattice_ci.r. This actually
        produces a p-value - you can read the code and the M&M paper to
        see if you like the way it is done (or if Paul likes the way it
        is done).
    4.  Calculate FDR, quantiles, etc: summarize_mm.r
        Steps 2-4 were all run from mm_2016-05-27.sh.
        IBEST directory: results/aln_geno_analysis/alignments/bowtie2_rapture_2015_allref_150904/next/aln_filter/2016-01-13/next/af_est/angsd_2016-03-13/next/time_series/mm_2016-05-27/results
    5.  Adjust p-values based on "genomic inflation factor." I read that
        this was a good idea in that Molec Ecol paper that discusses
        making genome scans more accurate, and I was trying to do
        everything correctly.  I don't really know if it's a good idea -
        it may over-adjust or it may be better not to get caught up in
        p-values. Anyway, the script that does the adjusting is called
        genomic_inflation_correction.r, and it assumes a one degree of
        freedom analysis. It uses the fdrtool package to calculate FDR
        values for each SNP too. This final step was part of the same
        script and output directory as the final step of the allele
        frequency change analysis.

spatpg
-------

    This is the fanciest analysis of the bunch. I suggest you read the
    paper about it (Gompert 2016, Bayesian inference of selection...),
    because it's been awhile since I've thought about it. Basically, you
    give it allele counts from multiple populations sampled at multiple
    time points along with an environmental factor that you think
    the populations may be adapting to. Then, it tries to figure which
    loci are under selection imposed by that environmental factor. It
    also tries to estimate Ne. In our case, the environmental factor was
    presence or absence of DFTD, so I was able to use all seven
    populations (Woolnorth is the seventh); the posterior Ne
    distribution just reflected the priors, so it was not able to
    estimate Ne. Because this analysis is the fanciest and also I had a
    lot of trouble getting it to run, I trust it the least, but make
    your own judgment.

    Workflow:
    1.  Estimate allele frequencies with ANGSD. Same as M&M analysis.
    2.  Convert allele frequencies into allele counts. Same filters as
        the M&M analysis. Note that the script that ran this step has
        some comment about LD thinning, but this was not actually run.
        The data were split randomly into 18 chunks before running the
        program. This was to prevent the program from taking too long or
        crashing. I had to do this randomly, because spatpg starts by
        estimating Ne from all SNPs, so you don't want to just grab one
        part of the genome.
    3.  Make DFTD the environmental parameter: Every year up to the
        first year with DFTD was given a value of -1, after the first
        year was given a value of 1. Just as with the M&M analysis, this
        is based on the year of birth of an individual.
    4.  Run spatpg: 100,000 steps, 10,000 burnin, Ne uniform prior
        between 25 and 40, otherwise default options, but some of these
        options could be important to adjust.
    5.  Calculate pseudo-p-values. I used the method recommended in the
        paper or manual, which is to calculate the proportion of MCMC
        steps for which beta > 0 or < 0, whichever was smaller - this
        became the p-value. Beta is basically a regression coefficient
        that "describes the relationship between the environmental
        covariate and selection experienced by a locus". Note that each
        locus has its own posterior distribution of beta. The script
        that did this calculation is summarize_spatpg.r. Steps 2-5 were
        all run by this batch script: spatpg_2016-03-14a.
    6.  Adjust the "p-values" as described for the M&M analyses. The
        differences are that the p-values were doubled (to convert from
        one-tailed to two-tailed) and that p-values of 0 were changed to
        a small number and p-values of 1 were changed to 0.9999 to avoid
        breaking some downstream steps. Again, same scripts and output
        directory as the final step for the other analyses.

Composite stats
----------------
 
    I combined some of the p-values and "p-values" into a composite
    statistic using the DCMS method of Ma et al. (2015 in Heredity). The
    script that does the calculations is css.r, and it takes a weighted
    sum of transformed p-values, where the weights are proportional to
    how much each statistic is correlated to the others. The
    transformation is log((1 - p) / p). Because not all methods produce
    a result at every SNP, I divide the composite score by the number of
    methods defined to get a mean composite score. This step was also
    run by composite_stat_2016-10-17.sh.


THE ACTUAL FILES YOU WANTED
============================

    Annotation file: biomart_reduced.bed

        You can use bedtools to get annotations for any of the
        "adjusted" files listed below by just taking the first four
        columns and getting rid of the header. I'm guessing you already
        have this file and already know how to do that, but I'm
        including it anyway.

    All of the files below have one line per SNP:

    Allele frequency change: <population>.afchange.adjusted.tsv

        To get the top variants you can sort ascending on "adjp" or
        descending on "quantile" or abs("score"). The score column is
        the change in allele frequency - I think it is the change in the
        freq.  of the reference allele. Note that "start" is the 0-based
        SNP coordinate, and "end" is the 1-based coordinate. Not all
        variants passed filters in every population.

    M&M analysis: <population>.mm.adjusted.tsv

    Columns:
        "score": measure of strength of selection; supposed to be how
            many times more fit the higher fitness allele is compared to
            the lower fitness allele (I think - it's been a while). The
            + and - indicate whether the reference or alternate allele
            is most fit.
        "p": original p-value from the analysis
        "q": FDR for original p-values
        "adjp": p-value after genomic inflation correction. For these
            analyses, the correction actually made p-values more
            significant.
        "fdr": FDR after inflation correction. Also calculated by
            fdrtool.

    Spatpg: spatpg.adjusted.tsv

        Same columns as above, but remember I used a sort of
        pseudo-p-value.

    Combinations:
        Look at the "mean_composite" column; larger numbers are stronger
        evidence.

        composite.snps.afchange: composite of all allele frequency
            change results. Had to have AF change data from >= 4 pops to
            include (no more than one missing).
        composite.snps.timeseries: composite of M&M and spatpg. Each run
            is treated as a separate result, so the spatpg results count
            as much as one population's worth of M&M results. Had to
            have results from >= 5 tests (no more than two missing) to
            include.


RECOMMENDATIONS
=================
 
    All of these tests may have some value, but I like the allele
    frequency change results the best because they are simple and
    because there are relatively few parameters that could be adjusted.
    The p-values, whether "real" or psuedo, should be treated with
    caution, and I don't really know whether the composite statistic is
    worthwhile. I was initially enthusiastic, but now I have the feeling
    that it could convert useful individual analyses into nonsense. It
    may be most useful in situations for which all the analyses are
    testing for the same thing in different ways - maybe this is true of
    my selection analyses, but it requires some thinking from someone
    smarter than me to figure it out. If the analyses aren't really
    aimed at the same thing (e.g. GWAS and selection results), then I
    think it doesn't work well.
